{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 problems"
   ],
   "id": "0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Ehrenfests' Fleas"
   ],
   "id": "1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "In this question you will:\n",
    "\n",
    "- study a Markov chain and analyse its properties\n",
    "- verify the analysed behaviour by comparing to Monte Carlo simulations\n",
    "- observe the emergence of a second law of thermodynamics\n"
   ],
   "id": "2"
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Ehrenfest has two dogs upon which $N$ fleas are distributed: $N_1$ on dog 1, and $N_2 = N - N_1$ on dog 2. We consider the microstate of the system to be $x = \\{ x_1, x_2, ... x_N \\}$, where $x_i = 1 ,  2$ indicates whether the $i$-th flea is on the first or second dog. In this sense, the number of fleas on each dog $N_1 + N_2 = N$ is a macrostate. This is a system whose statistics you have now studied to death in another guise: you should know the resulting multiplicity $g(N_1, N)$ and why it limits to a Gaussian when $N$ is large.\n",
    "\n",
    "However, in this problem we are going to study dynamics. You can think of it as a very crude version of the Newton's laws or Schroedinger equation which  govern  the microstates of real physical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. "
   ],
   "id": "5"
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Consider the following random process. At each point in time,  randomly pick one of the $N$ fleas, and have it hop to the opposite dog. If $x(t)$ is the configuration of fleas at time $t$, this defines a probabilistic process for updating the flea configuration, $x(t) \\to x(t+1)$. Write a function which takes as input length-$N$ array $x$, and which returns an updated configuration of fleas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "flags": [
     "problems"
    ]
   },
   "outputs": [],
   "source": [
    "def hop_flea(x):\n",
    "\n",
    "    N = len(x)\n",
    "\n",
    "    #do a random hop\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Write your answer here"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. "
   ],
   "id": "9"
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Starting from a configuration $x(0)$ in which all $N = 50$ fleas are on dog 1, use a for loop to succesively `hop_fleas` for $T = 20N$ time steps. At each iteration, log the number of fleas on dog 1, $N_1(t)$. \n",
    "Plot $N_1(t)$ vs $t$. How would you describe its behavior? Letting $S = \\ln g(N_1, N)$ be the dimensionless version of entropy, produce a second plot showing $S(t)$. \n",
    "\n",
    "Repeat for $N=100,200,500$. Comment on the statement \"entropy always increases\" as it applies to this problem and to macroscopic systems."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Write your answer here"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. "
   ],
   "id": "12"
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Now, starting from the same $x(0)$ for $N=50$, evolve for $T=5000$ steps, logging $N_1(t)$ as before. \n",
    "Plot a histogram of $N_1(t)$ for the last $T/2$ time steps. Using what you know about random walks / binary systems, compare it against the expected probability distrubiton $P(N_1, N)$ (either the exact one, or within the Gaussian approximation.)   Why did I have you produce the histogram using only steps $T/2 < t  \\leq T$, rather than including the first $T/2$ steps?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Write your answer here"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "14"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. "
   ],
   "id": "15"
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "Formally, the above process defines what we call a \"Markov Process.\" A Markov process is just a random sequence at each point in time, the probability of a state at the next moment in time depends only on the current state, not the past history.  We call the probability to be in state $x(t+1)$ at time $t+1$, given that we were in state $x(t)$ at time $t$, the \"transition matrix'' $\\mathcal{T}(x(t+1) | x(t))$.  You can think of it as a matrix because if you number the microstates, $i = x(t+1)$ and $j = x(t)$, then we read it like a matrix $\\mathcal{T}_{ij}$.  \n",
    "\n",
    "What is $\\mathcal{T}(x(t+1) | x(t))$? Your answer can read like an if-else statement, \"If $x(t+1)$ relates to $x(t)$ in this way, $\\mathcal{T}$ is blah, otherwise blech\". What is the size of this matrix? For $N=50$, would your datahub server have enough RAM to store it?\n",
    "\n",
    "For a great intro to the theory of Markov Processes, which play a huge role in statistical physics - and statistics / data science more generally - see Andrew Charman's excellent notes here: https://github.com/berkeley-physics/supplamental_materials/blob/master/acharman/MCMC.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here"
   ],
   "id": "17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e. "
   ],
   "id": "18"
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "In the above simulation, we keep track of the entire microstate. A quicker way to go about things would be to just keep track of $N_1$. Assuming the same flea hopping procedure as above, what is $\\mathcal{T}(N_1(t+1) | N_1(t) ) $? E.g., if there are $N_1(t)$ fleas on dog 1 at time $t$, and then you do hop_fleas, what is the probability to now have $N_1(t+1)$? This is now a much smaller $N+1$-dimensional matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here"
   ],
   "id": "20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f. "
   ],
   "id": "21"
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "flags": [
     "problems",
     "solutions"
    ]
   },
   "source": [
    "To check your answer, write a new function which takes in the current value of $N_1$, and then uses a random number to generate a new value of $N_1$ according to $\\mathcal{T}(N_1(t+1) | N_1(t) )$:\n",
    "\n",
    "```\n",
    "def fast_hop_flea(N1, N):\n",
    "    \n",
    "    (...do stuff...)\n",
    "    \n",
    "    return N1_new\n",
    "```\n",
    "    \n",
    "Now repeat all of b,c, with $N_1(0) = N$, but this time keep track only of $N_1(t)$ and use `fast_hop_flea`. Does the result agree? For $N = 50$ it may not literally be faster, but it would be for $N = 10^{23}$ !"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Write your answer here"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
